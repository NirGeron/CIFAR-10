# -*- coding: utf-8 -*-
"""imagesProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GwuXVOGWeo5RtqhEJ04tFFlzZSy___b-
"""

# Splitting the data into train, validation, and test

import pandas as pd
from sklearn.model_selection import train_test_split

# 1️⃣ Load the labels file
df = pd.read_csv('Labels.csv')  # Load the CSV file containing the labels

# 2️⃣ First split: Train (70%) and Temp (30%)
train_df, temp_df = train_test_split(
    df,
    test_size=0.3,          # 30% of the data will be split into Validation and Test
    random_state=42,        # Ensures the split is reproducible
    stratify=df['label']    # Ensures the label distribution remains balanced
)

# 3️⃣ Second split: Validation (15%) and Test (15%)
val_df, test_df = train_test_split(
    temp_df,
    test_size=0.5,          # Split Temp into 50% Validation and 50% Test
    random_state=42,        # Ensures reproducibility
    stratify=temp_df['label']  # Maintains balanced label distribution
)

# 4️⃣ Save the splits as CSV files
train_df.to_csv('train_split.csv', index=False)  # Save training split
val_df.to_csv('val_split.csv', index=False)      # Save validation split
test_df.to_csv('test_split.csv', index=False)    # Save test split

# 5️⃣ Print a summary of the splits
print("Train size:", len(train_df))    # Print the number of training samples
print("Validation size:", len(val_df))  # Print the number of validation samples
print("Test size:", len(test_df))       # Print the number of test samples

# Checking the number of items in each split (train, validation, and test)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the split datasets
train_df = pd.read_csv('train_split.csv')  # Load the training set
val_df = pd.read_csv('val_split.csv')      # Load the validation set
test_df = pd.read_csv('test_split.csv')    # Load the test set

# Check the size of each set
print(f"Train set size: {len(train_df)}")       # Print the number of training samples
print(f"Validation set size: {len(val_df)}")    # Print the number of validation samples
print(f"Test set size: {len(test_df)}")         # Print the number of test samples

# Check label distribution in each set
print("\nTrain set label distribution:")        # Print label distribution in the training set
print(train_df['label'].value_counts())

print("\nValidation set label distribution:")   # Print label distribution in the validation set
print(val_df['label'].value_counts())

print("\nTest set label distribution:")         # Print label distribution in the test set
print(test_df['label'].value_counts())

# Show the split of the data using graphs

# Train set distribution
plt.figure(figsize=(12, 4))  # Set the figure size for the plot
sns.countplot(data=train_df, x='label')  # Create a bar plot for the label distribution in the train set
plt.title('Train Set Distribution')  # Add a title to the plot
plt.show()  # Display the plot

# Validation set distribution
plt.figure(figsize=(12, 4))  # Set the figure size for the plot
sns.countplot(data=val_df, x='label')  # Create a bar plot for the label distribution in the validation set
plt.title('Validation Set Distribution')  # Add a title to the plot
plt.show()  # Display the plot

# Test set distribution
plt.figure(figsize=(12, 4))  # Set the figure size for the plot
sns.countplot(data=test_df, x='label')  # Create a bar plot for the label distribution in the test set
plt.title('Test Set Distribution')  # Add a title to the plot
plt.show()  # Display the plot

# BaseLine Model

import pandas as pd
from collections import Counter

# 1️⃣ Load the data
train_df = pd.read_csv('train_split.csv')  # Load the training dataset
test_df = pd.read_csv('test_split.csv')    # Load the test dataset

# 2️⃣ Find the most common label in the training set
label_counts = Counter(train_df['label'])  # Count the occurrences of each label
most_common_label = label_counts.most_common(1)[0][0]  # Get the most common label
most_common_count = label_counts.most_common(1)[0][1]  # Get the count of the most common label

print(f"📊 Most common label in Train: {most_common_label} (Count: {most_common_count})")

# 3️⃣ Calculate metrics for the Test Set
test_labels = test_df['label']  # Extract the labels from the test set

# Calculate True Positives (TP), False Positives (FP), False Negatives (FN), and True Negatives (TN)
TP = sum(label == most_common_label for label in test_labels)  # Count correct predictions for the most common label
FP = len(test_labels) - TP  # False positives: Incorrect predictions for other labels
FN = sum((label == most_common_label) for label in train_df['label']) - TP  # False negatives: Missed predictions for the most common label
TN = len(test_labels) - TP - FP  # True negatives: Correct predictions for other labels

# Calculate Precision, Recall, Accuracy, and F1-Score
precision = TP / (TP + FP) if (TP + FP) > 0 else 0  # Precision: TP / (TP + FP)
recall = TP / (TP + FN) if (TP + FN) > 0 else 0  # Recall: TP / (TP + FN)
accuracy = (TP + TN) / len(test_labels) if len(test_labels) > 0 else 0  # Accuracy: (TP + TN) / Total
f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0  # F1-Score formula

# Print the metrics
print(f"✅ Precision: {precision:.4f}")
print(f"✅ Recall: {recall:.4f}")
print(f"✅ Accuracy: {accuracy:.4f}")
print(f"✅ F1-Score: {f1_score:.4f}")

# Unzip all the images into a folder called "images"

import zipfile
import os
import shutil

# Create a new folder named 'images'
os.makedirs('/content/images', exist_ok=True)  # Ensure the folder exists (create if not)

# Extract the zip file into the 'images' folder
with zipfile.ZipFile('/content/train.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/images')  # Extract all files into the specified directory

# The extracted folder has a subfolder named 'train'. Move its content to 'images'.
train_folder = '/content/images/train'  # Path to the extracted 'train' folder
new_name = '/content/images/images'     # Final name of the main images folder

# Check if the 'train' folder exists
if os.path.exists(train_folder):
    # Move all contents from the 'train' folder to 'images'
    for item in os.listdir(train_folder):  # Iterate through all items in the 'train' folder
        s = os.path.join(train_folder, item)  # Source path of the item
        d = os.path.join('/content/images', item)  # Destination path
        if os.path.isdir(s):  # Check if the item is a folder
            shutil.copytree(s, d)  # Copy the entire folder and its contents
        else:  # If it's a file
            shutil.copy2(s, d)  # Copy the file

    # Remove the original 'train' folder to clean up
    shutil.rmtree(train_folder)

# Verify the new folder name
print(f"New folder name: {new_name}")

# Checking the number of images in the unzipped folder to ensure it contains 50K images

num_files = len(os.listdir('/content/images'))  # Count the number of files in the 'images' folder
print(f"✅ Number of images in '/content/images': {num_files}")  # Print the total number of images

# Softmax Reggretion Model


import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import StandardScaler, LabelEncoder
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import pandas as pd
import os

# 1. Load images and prepare data
def load_image(image_path):
    img = Image.open(image_path).resize((32, 32))  # Resize to 32x32
    return np.array(img).flatten()  # Convert to array and flatten

# Load image paths from training and testing CSV files
train_df = pd.read_csv('/content/train_split.csv')
test_df = pd.read_csv('/content/test_split.csv')

train_images = [load_image(os.path.join('/content/images', f"{img_name}.png")) for img_name in train_df['id']]
test_images = [load_image(os.path.join('/content/images', f"{img_name}.png")) for img_name in test_df['id']]

# Convert images into numerical arrays
X_train = np.array(train_images)
X_test = np.array(test_images)

# Standardize the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Convert to PyTorch tensors
X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)
X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)

# Encode the labels
label_encoder = LabelEncoder()
train_labels_encoded = label_encoder.fit_transform(train_df['label'].values)
test_labels_encoded = label_encoder.transform(test_df['label'].values)

train_labels_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)
test_labels_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)

# 2. Define the Softmax Regression model
class SoftmaxRegressionModel(nn.Module):
    def __init__(self, input_dim, output_dim, dropout_rate=0.5):
        super(SoftmaxRegressionModel, self).__init__()
        self.fc = nn.Linear(input_dim, output_dim)  # Single linear layer
        self.dropout = nn.Dropout(p=dropout_rate)  # Dropout layer

    def forward(self, x):
        x = self.dropout(x)  # Apply dropout
        return self.fc(x)  # Linear transformation

# Model parameters
input_dim = X_train_tensor.shape[1]  # Number of input features (3072 for 32x32 RGB images)
output_dim = len(np.unique(train_labels_encoded))  # Number of categories
dropout_rate = 0.5

# Initialize the model
model = SoftmaxRegressionModel(input_dim, output_dim, dropout_rate)

# 3. Define loss function and optimizer
criterion = nn.CrossEntropyLoss()  # Loss function for multiclass classification
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # Add weight decay for regularization

# 4. Early Stopping parameters
patience = 5  # Number of epochs without improvement before stopping
no_improvement_count = 0  # Counter for epochs without improvement
best_val_loss = float('inf')  # Best validation loss initialized to infinity

# 5. Training loop
num_epochs = 200
train_losses, val_losses = [], []
train_accuracies, val_accuracies = [], []

for epoch in range(num_epochs):
    # Training step
    model.train()
    optimizer.zero_grad()
    output = model(X_train_tensor)
    loss = criterion(output, train_labels_tensor)
    loss.backward()
    optimizer.step()

    # Calculate training accuracy
    _, predicted_train = torch.max(output, 1)
    train_accuracy = (predicted_train == train_labels_tensor).float().mean().item()

    # Store training loss and accuracy
    train_losses.append(loss.item())
    train_accuracies.append(train_accuracy)

    # Validation step
    model.eval()
    with torch.no_grad():
        output_val = model(X_test_tensor)
        val_loss = criterion(output_val, test_labels_tensor)

        _, predicted_val = torch.max(output_val, 1)
        val_accuracy = (predicted_val == test_labels_tensor).float().mean().item()

        # Store validation loss and accuracy
        val_losses.append(val_loss.item())
        val_accuracies.append(val_accuracy)

    # Check for improvement in validation loss
    if val_loss.item() < best_val_loss:
        best_val_loss = val_loss.item()
        no_improvement_count = 0
    else:
        no_improvement_count += 1

    # Print epoch details
    print(f"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, "
          f"Train Accuracy: {train_accuracy:.4f}, Validation Loss: {val_loss.item():.4f}, "
          f"Validation Accuracy: {val_accuracy:.4f}")

    # Early stopping
    if no_improvement_count >= patience:
        print(f"Early stopping triggered at epoch {epoch + 1}")
        break

# 6. Plot Loss and Accuracy graphs
plt.figure(figsize=(12, 6))
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Validation Loss')
plt.title('Train vs Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid()
plt.show()

plt.figure(figsize=(12, 6))
plt.plot(train_accuracies, label='Train Accuracy')
plt.plot(val_accuracies, label='Validation Accuracy')
plt.title('Train vs Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid()
plt.show()

# Testing the regression model

from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score  # Import necessary metrics

#Perform a test on the model after training

# Set the model to evaluation mode
model.eval()

# Make predictions on the test set
with torch.no_grad():  # Disable gradient calculations during evaluation
    output_test = model(X_test_tensor)  # Compute predictions for the test set
    _, predicted_test = torch.max(output_test, 1)  # Get predicted classes

    # Calculate accuracy on the test set
    test_accuracy = accuracy_score(test_labels_tensor, predicted_test)
    print(f"Test Accuracy: {test_accuracy:.4f}")

    # Calculate Precision, Recall, and F1-Score on the test set
    test_precision = precision_score(test_labels_tensor, predicted_test, average='weighted')
    test_recall = recall_score(test_labels_tensor, predicted_test, average='weighted')
    test_f1 = f1_score(test_labels_tensor, predicted_test, average='weighted')

    print(f"Test Precision: {test_precision:.4f}")
    print(f"Test Recall: {test_recall:.4f}")
    print(f"Test F1-Score: {test_f1:.4f}")

#FNN MODEL

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms
from sklearn.preprocessing import StandardScaler, LabelEncoder
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import pandas as pd
import os
from sklearn.metrics import accuracy_score

# 1. Loading images and preparing data (convert images to numerical arrays)
def load_image(image_path):
    img = Image.open(image_path).resize((32, 32))  # Resize the image to 32x32 pixels
    return np.array(img)  # Convert the image to a numerical array

# Augmentation for the training set
train_transform = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip the image horizontally with a 50% chance
    transforms.RandomRotation(degrees=10),  # Randomly rotate the image within a range of ±10 degrees
    transforms.RandomResizedCrop(size=32, scale=(0.8, 1.0)),  # Randomly crop and resize the image
    transforms.ToTensor(),  # Convert the image to a PyTorch tensor
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the pixel values to [-1, 1]
])

# Simple augmentation for the test set
test_transform = transforms.Compose([
    transforms.ToTensor(),  # Convert the image to a PyTorch tensor
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the pixel values to [-1, 1]
])


def process_images(dataframe, images_path, transform):
    images = []  # Initialize an empty list to store processed images
    for img_name in dataframe['id']:  # Loop through image IDs in the dataframe
        image_path = os.path.join(images_path, f"{img_name}.png")  # Construct the full image path
        img = Image.open(image_path).resize((32, 32))  # Open and resize the image to 32x32 pixels
        img_tensor = transform(img)  # Apply the specified transformations (e.g., normalization, augmentation)
        images.append(img_tensor)  # Add the transformed image tensor to the list
    return torch.stack(images)  # Stack all image tensors into a single tensor

# Paths to the training and test images
train_images_path = '/content/images'
test_images_path = '/content/images'

# Load the dataframes containing image IDs and labels
train_df = pd.read_csv('/content/train_split.csv')  # Training data
test_df = pd.read_csv('/content/test_split.csv')  # Test data

# Process images with transformations
X_train_tensor = process_images(train_df, train_images_path, train_transform)  # Training images
X_test_tensor = process_images(test_df, test_images_path, test_transform)  # Test images

# 2. Encoding labels (converting categorical labels to numerical labels)
label_encoder = LabelEncoder()  # Initialize the label encoder
train_labels_encoded = label_encoder.fit_transform(train_df['label'].values)  # Fit and transform training labels
test_labels_encoded = label_encoder.transform(test_df['label'].values)  # Transform test labels

# Convert encoded labels to PyTorch tensors
train_labels_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)  # Training labels tensor
test_labels_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)  # Test labels tensor

# 3. The model class
class FNNModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(FNNModel, self).__init__()

        # First hidden layer
        self.fc1 = nn.Linear(input_dim, hidden_dim)  # Fully connected layer: input -> hidden_dim
        self.bn1 = nn.BatchNorm1d(hidden_dim)       # Batch normalization for stabilizing training
        self.dropout1 = nn.Dropout(p=0.5)          # Dropout for regularization (50% chance to drop neurons)
        self.relu1 = nn.ReLU()                     # Activation function (ReLU)

        # Second hidden layer
        self.fc2 = nn.Linear(hidden_dim, hidden_dim)  # Fully connected layer: hidden_dim -> hidden_dim
        self.bn2 = nn.BatchNorm1d(hidden_dim)         # Batch normalization
        self.dropout2 = nn.Dropout(p=0.5)            # Dropout
        self.relu2 = nn.ReLU()                       # Activation function (ReLU)

        # Third hidden layer
        self.fc3 = nn.Linear(hidden_dim, hidden_dim)  # Fully connected layer: hidden_dim -> hidden_dim
        self.bn3 = nn.BatchNorm1d(hidden_dim)         # Batch normalization
        self.dropout3 = nn.Dropout(p=0.5)            # Dropout
        self.relu3 = nn.ReLU()                       # Activation function (ReLU)

        # Output layer
        self.fc4 = nn.Linear(hidden_dim, output_dim)  # Fully connected layer: hidden_dim -> output_dim

    def forward(self, x):
        # Pass input through the first hidden layer
        x = self.relu1(self.dropout1(self.bn1(self.fc1(x))))

        # Pass through the second hidden layer
        x = self.relu2(self.dropout2(self.bn2(self.fc2(x))))

        # Pass through the third hidden layer
        x = self.relu3(self.dropout3(self.bn3(self.fc3(x))))

        # Output layer (no activation here, handled by CrossEntropyLoss)
        x = self.fc4(x)
        return x

# Model creation
input_dim = 32 * 32 * 3  # Images are RGB with 32x32 pixels, flattened to a single vector
hidden_dim = 256  # Number of neurons in each hidden layer
output_dim = len(np.unique(train_labels_encoded))  # Number of unique labels (output classes)
model = FNNModel(input_dim, hidden_dim, output_dim)  # Initialize the FNN model

# 4. Loss function and optimizer definition
criterion = nn.CrossEntropyLoss()  # Cross-Entropy Loss for multi-class classification
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
# Adam optimizer with a learning rate of 0.001 and weight decay for regularization

# 5. Early stopping setup
patience = 10  # Number of epochs to wait before stopping if no improvement
no_improvement_count = 0  # Counter for epochs without improvement
best_val_loss = float('inf')  # Initialize the best validation loss to infinity

# 6. Training setup
num_epochs = 200  # Maximum number of training epochs
train_losses, val_losses = [], []  # Lists to store training and validation losses
train_accuracies, val_accuracies = [], []  # Lists to store training and validation accuracies


for epoch in range(num_epochs):  # Loop through each epoch
    model.train()  # Set the model to training mode (activates Dropout, BatchNorm)
    optimizer.zero_grad()  # Clear gradients from the previous step

    # Forward pass: Compute the model's output for the training data
    output = model(X_train_tensor.view(X_train_tensor.size(0), -1))  # Flatten the input
    loss = criterion(output, train_labels_tensor)  # Compute the loss (CrossEntropyLoss)

    # Backward pass: Compute gradients
    loss.backward()
    optimizer.step()  # Update the model's parameters using the optimizer

    # Calculate training accuracy
    _, predicted_train = torch.max(output, 1)  # Get the predicted classes
    train_accuracy = accuracy_score(train_labels_tensor, predicted_train)  # Compare with true labels

    # Record training loss and accuracy
    train_losses.append(loss.item())
    train_accuracies.append(train_accuracy)

    # Validation step
    model.eval()  # Set the model to evaluation mode (deactivates Dropout)
    with torch.no_grad():  # Disable gradient computation for efficiency
        # Forward pass on validation data
        output_val = model(X_test_tensor.view(X_test_tensor.size(0), -1))
        val_loss = criterion(output_val, test_labels_tensor)  # Compute validation loss
        _, predicted_val = torch.max(output_val, 1)  # Get predicted classes for validation
        val_accuracy = accuracy_score(test_labels_tensor, predicted_val)  # Compare with true labels

        # Record validation loss and accuracy
        val_losses.append(val_loss.item())
        val_accuracies.append(val_accuracy)

    # Early stopping logic
    if val_loss.item() < best_val_loss:  # Check if validation loss improved
        best_val_loss = val_loss.item()  # Update the best validation loss
        no_improvement_count = 0  # Reset the counter
    else:
        no_improvement_count += 1  # Increment the counter if no improvement

    # Print progress for the current epoch
    print(f"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, "
          f"Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss.item():.4f}, "
          f"Val Accuracy: {val_accuracy:.4f}")

    # Stop training if no improvement for 'patience' epochs
    if no_improvement_count >= patience:
        print("Early stopping triggered.")
        break


# Plotting graphs to visualize training and validation metrics

# Plotting loss for training and validation
plt.figure(figsize=(12, 6))  # Set the figure size
plt.plot(train_losses, label="Train Loss")  # Plot training loss
plt.plot(val_losses, label="Validation Loss")  # Plot validation loss
plt.legend()  # Add a legend to differentiate the lines
plt.title("Train vs Validation Loss")  # Add a title to the plot
plt.show()  # Display the plot

# Plotting accuracy for training and validation
plt.figure(figsize=(12, 6))  # Set the figure size
plt.plot(train_accuracies, label="Train Accuracy")  # Plot training accuracy
plt.plot(val_accuracies, label="Validation Accuracy")  # Plot validation accuracy
plt.legend()  # Add a legend to differentiate the lines
plt.title("Train vs Validation Accuracy")  # Add a title to the plot
plt.show()  # Display the plot

# Testing the FNN Model

from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

# Flatten the test data to match the input dimensions of the model
X_test_flattened = X_test_tensor.view(X_test_tensor.size(0), -1)

# Set the model to evaluation mode
model.eval()

# Initialize lists to store results
test_losses = []
test_accuracies = []

# Calculate loss and metrics on the test set
with torch.no_grad():  # Disable gradient computation during testing
    output_test = model(X_test_flattened)  # Compute predictions for the test set
    test_loss = criterion(output_test, test_labels_tensor)  # Calculate the test loss

    # Get the predicted labels
    _, predicted_test = torch.max(output_test, 1)

    # Calculate metrics
    test_accuracy = accuracy_score(test_labels_tensor.cpu(), predicted_test.cpu())
    test_precision = precision_score(test_labels_tensor.cpu(), predicted_test.cpu(), average='weighted')
    test_recall = recall_score(test_labels_tensor.cpu(), predicted_test.cpu(), average='weighted')
    test_f1 = f1_score(test_labels_tensor.cpu(), predicted_test.cpu(), average='weighted')

    # Store test results
    test_losses.append(test_loss.item())
    test_accuracies.append(test_accuracy)

# Print the test metrics
print(f"Test Loss: {test_loss.item():.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")
print(f"Test Precision: {test_precision:.4f}")
print(f"Test Recall: {test_recall:.4f}")
print(f"Test F1-Score: {test_f1:.4f}")

# CNN Model
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as transforms
import numpy as np
from PIL import Image
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
import matplotlib.pyplot as plt



############################################################
# Function to save Checkpoints
############################################################
def save_checkpoint(model, optimizer, epoch, train_loss, val_loss, train_acc, val_acc, filepath="content/checkpoint.pth"):
    '''
    Saves the model's current state, optimizer state, and training metrics
    (loss and accuracy for both train and validation) to a file.
    '''
    torch.save({
        'epoch': epoch,                                 # Current epoch number
        'model_state_dict': model.state_dict(),         # Model parameters
        'optimizer_state_dict': optimizer.state_dict(), # Optimizer parameters
        'train_loss': train_loss,                       # Training loss at the current epoch
        'val_loss': val_loss,                           # Validation loss at the current epoch
        'train_acc': train_acc,                         # Training accuracy at the current epoch
        'val_acc': val_acc,                             # Validation accuracy at the current epoch
    }, filepath)                                        # Filepath to save the checkpoint
    print(f"Checkpoint saved at epoch {epoch} in {filepath}") # Confirmation message


def load_checkpoint(model, optimizer, filepath="content/checkpoint.pth"):
    '''
    Loads a saved checkpoint, restoring the model's parameters,
    optimizer's parameters, and training metrics.
    '''
    checkpoint = torch.load(filepath)                      # Load the checkpoint file
    model.load_state_dict(checkpoint['model_state_dict'])  # Restore model parameters
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])  # Restore optimizer parameters
    epoch = checkpoint['epoch']                            # Retrieve the epoch number
    train_loss = checkpoint['train_loss']                  # Retrieve the training loss
    val_loss = checkpoint['val_loss']                      # Retrieve the validation loss
    train_acc = checkpoint['train_acc']                    # Retrieve the training accuracy
    val_acc = checkpoint['val_acc']                        # Retrieve the validation accuracy

    print(f"Checkpoint loaded from epoch {epoch}")         # Confirmation message
    return epoch, train_loss, val_loss, train_acc, val_acc  # Return all retrieved values


# Convert labels to numerical values
label_encoder = LabelEncoder()  # Initialize a label encoder
train_df['label'] = label_encoder.fit_transform(train_df['label'])  # Fit and transform training labels
val_df['label'] = label_encoder.transform(val_df['label'])          # Transform validation labels
test_df['label'] = label_encoder.transform(test_df['label'])        # Transform test labels




# Custom Dataset class for handling image data
class ImageDataset(Dataset):
    '''
    A custom PyTorch Dataset to handle image data and their corresponding labels.
    '''
    def __init__(self, dataframe, images_folder, transform=None):
        '''
        Initializes the dataset.
        Args:
            dataframe: A pandas DataFrame containing image IDs and labels.
            images_folder: Path to the folder containing the images.
            transform: Optional transformations to apply to the images.
        '''
        self.dataframe = dataframe                # Store the dataframe
        self.images_folder = images_folder        # Store the images folder path
        self.transform = transform                # Store the transformations

    def __len__(self):
        '''
        Returns the total number of samples in the dataset.
        '''
        return len(self.dataframe)

    def __getitem__(self, idx):
        '''
        Retrieves an image and its corresponding label by index.
        Args:
            idx: Index of the sample to retrieve.
        Returns:
            image: Transformed image tensor.
            label: Corresponding label as a torch tensor.
        '''
        img_name = self.dataframe.iloc[idx]['id']  # Get the image ID
        label = self.dataframe.iloc[idx]['label']  # Get the label
        img_path = f"{self.images_folder}/{img_name}.png"  # Construct the image path
        image = Image.open(img_path).convert("RGB")  # Load the image and convert to RGB
        if self.transform:                          # Apply transformations if provided
            image = self.transform(image)
        return image, torch.tensor(label, dtype=torch.long)  # Return image and label

############################################################
# 1) Data Augmentation (Transformations)
############################################################
train_transform = transforms.Compose([
    transforms.Resize((32, 32)),                 # Resize images to 32x32 pixels
    transforms.RandomHorizontalFlip(p=0.5),     # Apply horizontal flip with 50% probability
    transforms.RandomRotation(10),              # Apply random rotation up to 10 degrees
    transforms.ToTensor(),                       # Convert image to a tensor
    transforms.Normalize(mean=[0.5, 0.5, 0.5],  # Normalize the image: mean and std for each channel
                         std=[0.5, 0.5, 0.5])
])


# For validation and testing, use "neutral" transformations (without augmentation)
val_test_transform = transforms.Compose([
    transforms.Resize((32, 32)),                 # Resize images to 32x32 pixels
    transforms.ToTensor(),                       # Convert image to a tensor
    transforms.Normalize(mean=[0.5, 0.5, 0.5],  # Normalize the image: mean and std for each channel
                         std=[0.5, 0.5, 0.5])
])


# Load training, validation, and testing data with the defined transformations
train_dataset = ImageDataset(train_df, '/content/images', transform=train_transform)  # Apply training transformations
val_dataset   = ImageDataset(val_df,   '/content/images', transform=val_test_transform)  # Apply validation transformations
test_dataset  = ImageDataset(test_df,  '/content/images', transform=val_test_transform)  # Apply testing transformations

# Create DataLoaders for batching and shuffling data
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)  # Shuffle training data for randomness
val_loader   = DataLoader(val_dataset,   batch_size=64, shuffle=False)  # No shuffling for validation data
test_loader  = DataLoader(test_dataset,  batch_size=64, shuffle=False)  # No shuffling for testing data



############################################################
# 2) Adding Dropout to the Model
############################################################
class CNNModel(nn.Module):
    '''
    A Convolutional Neural Network (CNN) model with Batch Normalization
    and Dropout to prevent overfitting.
    '''
    def __init__(self, num_classes):
        '''
        Initializes the CNN model.
        Args:
            num_classes: Number of output classes for classification.
        '''
        super(CNNModel, self).__init__()
        # First convolutional layer: 3 input channels, 32 output filters
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)
        self.bn1 = nn.BatchNorm2d(32)  # Batch Normalization after Conv1

        # Second convolutional layer: 32 input filters, 64 output filters
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(64)  # Batch Normalization after Conv2

        # Third convolutional layer: 64 input filters, 128 output filters
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)
        self.bn3 = nn.BatchNorm2d(128)  # Batch Normalization after Conv3

        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling with 2x2 kernel

        self.flatten = nn.Flatten()  # Flatten the tensor for fully connected layers
        self.fc1 = nn.Linear(128 * 16 * 16, 128)  # First fully connected layer
        self.dropout_fc = nn.Dropout(p=0.5)  # Dropout with 50% probability
        self.fc2 = nn.Linear(128, num_classes)  # Output layer

    def forward(self, x):
        '''
        Defines the forward pass of the model.
        Args:
            x: Input tensor.
        Returns:
            Output logits for the given input.
        '''
        x = torch.relu(self.bn1(self.conv1(x)))  # Conv1 -> BatchNorm -> ReLU
        x = torch.relu(self.bn2(self.conv2(x)))  # Conv2 -> BatchNorm -> ReLU
        x = torch.relu(self.bn3(self.conv3(x)))  # Conv3 -> BatchNorm -> ReLU
        x = self.pool(x)  # Max Pooling

        x = self.flatten(x)              # Flatten for fully connected layers
        x = torch.relu(self.fc1(x))      # Fully Connected Layer 1 -> ReLU
        x = self.dropout_fc(x)           # Apply Dropout
        x = self.fc2(x)                  # Fully Connected Layer 2 (Output layer)
        return x


# Define the model, loss function, optimizer, and learning rate scheduler
num_classes = 10  # Number of output classes for classification
model = CNNModel(num_classes)  # Initialize the CNN model

# Initialize the optimizer with weight decay for regularization
# Uncomment the following line to use a different weight decay value
# optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # Adam optimizer with weight decay

# Initialize a learning rate scheduler
# Reduces the learning rate by 30% every 10 epochs
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)

# Define start_epoch based on whether a checkpoint is loaded
checkpoint_path = '/content/checkpoint.pth'
if os.path.exists(checkpoint_path):
    epoch, train_loss, val_loss, train_acc, val_acc = load_checkpoint(model, optimizer, checkpoint_path)
    print(f"Resumed training from epoch {epoch}")
    start_epoch = epoch + 1  # Continue from the next epoch
else:
    print("Starting training from scratch")
    start_epoch = 0  # Start from the first epoch

# Define the loss function
criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification



# Training function with metrics tracking
def train_model_with_metrics(model, train_loader, val_loader, num_epochs, device, patience=10):
    '''
    Trains a model while tracking metrics such as loss and accuracy for both
    training and validation. Implements early stopping based on validation loss.
    Args:
        model: The neural network model to train.
        train_loader: DataLoader for the training dataset.
        val_loader: DataLoader for the validation dataset.
        num_epochs: Total number of epochs for training.
        device: Device to use for training (CPU or GPU).
        patience: Number of epochs to wait without improvement before stopping.
    '''
    model.to(device)  # Move the model to the specified device
    train_losses, val_losses = [], []  # Lists to store training and validation losses
    train_accuracies, val_accuracies = [], []  # Lists to store training and validation accuracies

    best_val_loss = float('inf')  # Initialize the best validation loss to infinity
    epochs_without_improvement = 0  # Counter for epochs without improvement in validation loss

    for epoch in range(start_epoch, num_epochs):
        model.train()  # Set the model to training mode
        train_loss = 0.0  # Initialize training loss for the epoch
        train_correct = 0  # Initialize correct predictions counter for training

        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)  # Move data to the device
            optimizer.zero_grad()  # Clear previous gradients

            outputs = model(images)  # Forward pass
            loss = criterion(outputs, labels)  # Compute loss
            loss.backward()  # Backward pass
            optimizer.step()  # Update model parameters

            train_loss += loss.item() * images.size(0)  # Accumulate total training loss
            _, preds = torch.max(outputs, 1)  # Get predictions
            train_correct += torch.sum(preds == labels).item()  # Count correct predictions

        # Compute average training loss and accuracy for the epoch
        train_losses.append(train_loss / len(train_loader.dataset))
        train_accuracies.append(train_correct / len(train_loader.dataset))

        # Update learning rate using the scheduler
        scheduler.step()

        model.eval()  # Set the model to evaluation mode
        val_loss = 0.0  # Initialize validation loss
        val_correct = 0  # Initialize correct predictions counter for validation

        with torch.no_grad():  # Disable gradient computation
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)  # Move data to the device
                outputs = model(images)  # Forward pass
                loss = criterion(outputs, labels)  # Compute loss
                val_loss += loss.item() * images.size(0)  # Accumulate total validation loss
                _, preds = torch.max(outputs, 1)  # Get predictions
                val_correct += torch.sum(preds == labels).item()  # Count correct predictions

        # Compute average validation loss and accuracy for the epoch
        train_acc = train_correct / len(train_loader.dataset)
        val_acc = val_correct / len(val_loader.dataset)

        val_losses.append(val_loss / len(val_loader.dataset))
        val_accuracies.append(val_acc)

        # Early stopping logic
        if val_loss < best_val_loss:
            best_val_loss = val_loss  # Update the best validation loss
            epochs_without_improvement = 0  # Reset the counter
            # Save a checkpoint when validation loss improves
            checkpoint_path = '/content/checkpoint.pth'
            save_checkpoint(model, optimizer, epoch, train_loss, val_loss, train_acc, val_acc, filepath=checkpoint_path)
        else:
            epochs_without_improvement += 1  # Increment the counter if no improvement

        if epochs_without_improvement >= patience:
            print(f"Early stopping at epoch {epoch + 1}")  # Stop training early if no improvement
            break

        # Print training and validation metrics for the epoch
        print(f"Epoch [{epoch+1}/{num_epochs}], "
              f"Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accuracies[-1]:.4f}, "
              f"Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracies[-1]:.4f}")

    # Plot loss and accuracy graphs
    plt.figure(figsize=(10, 4))

    # Plot training vs validation loss
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label="Train Loss")
    plt.plot(val_losses, label="Validation Loss")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.legend()
    plt.title("Train vs Validation Loss")

    # Plot training vs validation accuracy
    plt.subplot(1, 2, 2)
    plt.plot(train_accuracies, label="Train Accuracy")
    plt.plot(val_accuracies, label="Validation Accuracy")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.title("Train vs Validation Accuracy")

    plt.tight_layout()
    plt.show()


# Train the model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")  # Use GPU if available, otherwise CPU
train_model_with_metrics(model, train_loader, val_loader, num_epochs=80, device=device)  # Train the model with 80 epochs

# Evaluate the model on the test dataset
def evaluate_model_with_metrics(model, test_loader, device):
    '''
    Evaluates the model on the test dataset and computes performance metrics.
    Args:
        model: The trained neural network model.
        test_loader: DataLoader for the test dataset.
        device: Device to use for evaluation (CPU or GPU).
    '''
    model.to(device)  # Move the model to the specified device
    model.eval()  # Set the model to evaluation mode
    all_labels = []  # List to store true labels
    all_preds = []  # List to store predicted labels

    with torch.no_grad():  # Disable gradient computation for evaluation
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)  # Move data to the device
            outputs = model(images)  # Forward pass
            _, preds = torch.max(outputs, 1)  # Get predictions with the highest probability
            all_labels.extend(labels.cpu().numpy())  # Store true labels
            all_preds.extend(preds.cpu().numpy())  # Store predicted labels

    # Calculate evaluation metrics
    precision = precision_score(all_labels, all_preds, average="weighted")  # Weighted precision
    recall = recall_score(all_labels, all_preds, average="weighted")  # Weighted recall
    f1 = f1_score(all_labels, all_preds, average="weighted")  # Weighted F1-score
    accuracy = accuracy_score(all_labels, all_preds)  # Overall accuracy

    # Print evaluation metrics
    print(f"Test Metrics:\n"
          f"Precision: {precision:.4f}\n"
          f"Recall: {recall:.4f}\n"
          f"F1-Score: {f1:.4f}\n"
          f"Accuracy: {accuracy:.4f}")

# Call the evaluation function
evaluate_model_with_metrics(model, test_loader, device)

# Printing the graph of the CNN model

"""
This script uses training logs to create graphs showing how the model performed during training.

Why use logs instead of checkpoints?
-------------------------------------
1. Long training sessions can stop because of time limits or disconnections.
2. Checkpoints only save the latest epoch, not the full training history.
3. Logs printed during training contain all the data (Train Loss, Validation Loss,
   Train Accuracy, Validation Accuracy) for every epoch.
4. By using these logs, we can recreate the full training history and plot graphs.

How to use:
-----------
1. Copy and paste the full training log (printed during training) into the `log` variable below.
2. Run the script to extract the data and plot the graphs.
"""


log = """
Starting training from scratch
Checkpoint saved at epoch 0 in /content/checkpoint.pth
Epoch [1/50], Train Loss: 2.3457, Train Accuracy: 0.1035, Val Loss: 2.2846, Val Accuracy: 0.1189
Checkpoint saved at epoch 1 in /content/checkpoint.pth
Epoch [2/50], Train Loss: 2.2560, Train Accuracy: 0.1221, Val Loss: 2.1225, Val Accuracy: 0.1796
Checkpoint saved at epoch 2 in /content/checkpoint.pth
Epoch [3/50], Train Loss: 2.2029, Train Accuracy: 0.1373, Val Loss: 2.0720, Val Accuracy: 0.1797
Checkpoint saved at epoch 3 in /content/checkpoint.pth
Epoch [4/50], Train Loss: 2.1880, Train Accuracy: 0.1437, Val Loss: 2.0709, Val Accuracy: 0.1833
Checkpoint saved at epoch 4 in /content/checkpoint.pth
Epoch [5/50], Train Loss: 2.1850, Train Accuracy: 0.1442, Val Loss: 2.0253, Val Accuracy: 0.2045
Epoch [6/50], Train Loss: 2.1810, Train Accuracy: 0.1438, Val Loss: 2.0436, Val Accuracy: 0.1824
Epoch [7/50], Train Loss: 2.1753, Train Accuracy: 0.1454, Val Loss: 2.0360, Val Accuracy: 0.1791
Epoch [8/50], Train Loss: 2.1726, Train Accuracy: 0.1467, Val Loss: 2.0406, Val Accuracy: 0.1961
Checkpoint saved at epoch 8 in /content/checkpoint.pth
Epoch [9/50], Train Loss: 2.1707, Train Accuracy: 0.1445, Val Loss: 2.0132, Val Accuracy: 0.1941
Checkpoint saved at epoch 9 in /content/checkpoint.pth
Epoch [10/50], Train Loss: 2.1666, Train Accuracy: 0.1478, Val Loss: 1.9972, Val Accuracy: 0.2073
Epoch [11/50], Train Loss: 2.1606, Train Accuracy: 0.1513, Val Loss: 2.0159, Val Accuracy: 0.1992
Epoch [12/50], Train Loss: 2.1603, Train Accuracy: 0.1511, Val Loss: 2.0127, Val Accuracy: 0.2029
Checkpoint saved at epoch 12 in /content/checkpoint.pth
Epoch [13/50], Train Loss: 2.1594, Train Accuracy: 0.1500, Val Loss: 1.9941, Val Accuracy: 0.1916
Checkpoint saved at epoch 13 in /content/checkpoint.pth
Epoch [14/50], Train Loss: 2.1553, Train Accuracy: 0.1509, Val Loss: 1.9847, Val Accuracy: 0.1996
Epoch [15/50], Train Loss: 2.1559, Train Accuracy: 0.1515, Val Loss: 2.0503, Val Accuracy: 0.1943
Checkpoint saved at epoch 15 in /content/checkpoint.pth
Epoch [16/50], Train Loss: 2.1120, Train Accuracy: 0.1620, Val Loss: 1.8492, Val Accuracy: 0.2276
Checkpoint saved at epoch 16 in /content/checkpoint.pth
Epoch [17/50], Train Loss: 2.0634, Train Accuracy: 0.1606, Val Loss: 1.8389, Val Accuracy: 0.2251
Checkpoint saved at epoch 17 in /content/checkpoint.pth
Epoch [18/50], Train Loss: 2.0544, Train Accuracy: 0.1555, Val Loss: 1.7975, Val Accuracy: 0.2111
Checkpoint saved at epoch 18 in /content/checkpoint.pth
Epoch [19/50], Train Loss: 2.0447, Train Accuracy: 0.1565, Val Loss: 1.7809, Val Accuracy: 0.2460
Checkpoint saved at epoch 19 in /content/checkpoint.pth
Epoch [20/50], Train Loss: 1.9805, Train Accuracy: 0.1892, Val Loss: 1.6607, Val Accuracy: 0.3319
Checkpoint saved at epoch 20 in /content/checkpoint.pth
Epoch [21/50], Train Loss: 1.9493, Train Accuracy: 0.2086, Val Loss: 1.6411, Val Accuracy: 0.3487
Epoch [22/50], Train Loss: 1.9334, Train Accuracy: 0.2132, Val Loss: 1.6493, Val Accuracy: 0.3623
Checkpoint saved at epoch 22 in /content/checkpoint.pth
Epoch [23/50], Train Loss: 1.8916, Train Accuracy: 0.2308, Val Loss: 1.5166, Val Accuracy: 0.4392
Checkpoint saved at epoch 23 in /content/checkpoint.pth
Epoch [24/50], Train Loss: 1.7767, Train Accuracy: 0.2767, Val Loss: 1.4304, Val Accuracy: 0.4897
Checkpoint saved at epoch 24 in /content/checkpoint.pth
Epoch [25/50], Train Loss: 1.7150, Train Accuracy: 0.3051, Val Loss: 1.3944, Val Accuracy: 0.5192
Checkpoint saved at epoch 25 in /content/checkpoint.pth
Epoch [26/50], Train Loss: 1.6230, Train Accuracy: 0.3452, Val Loss: 1.2568, Val Accuracy: 0.5687
Checkpoint saved at epoch 26 in /content/checkpoint.pth
Epoch [27/50], Train Loss: 1.5740, Train Accuracy: 0.3742, Val Loss: 1.2121, Val Accuracy: 0.5844
Checkpoint saved at epoch 27 in /content/checkpoint.pth
Epoch [28/50], Train Loss: 1.4787, Train Accuracy: 0.4236, Val Loss: 1.1405, Val Accuracy: 0.6183
Checkpoint saved at epoch 28 in /content/checkpoint.pth
Epoch [29/50], Train Loss: 1.4128, Train Accuracy: 0.4562, Val Loss: 1.0721, Val Accuracy: 0.6420
Checkpoint saved at epoch 29 in /content/checkpoint.pth
Epoch [30/50], Train Loss: 1.3700, Train Accuracy: 0.4737, Val Loss: 1.0323, Val Accuracy: 0.6665
Checkpoint saved at epoch 30 in /content/checkpoint.pth
Epoch [31/50], Train Loss: 1.3171, Train Accuracy: 0.4991, Val Loss: 0.9942, Val Accuracy: 0.6679
Checkpoint saved at epoch 31 in /content/checkpoint.pth
Epoch [32/50], Train Loss: 1.2551, Train Accuracy: 0.5187, Val Loss: 0.9468, Val Accuracy: 0.6765
Checkpoint saved at epoch 32 in /content/checkpoint.pth
Epoch [33/50], Train Loss: 1.2162, Train Accuracy: 0.5388, Val Loss: 0.9209, Val Accuracy: 0.6915
Checkpoint saved at epoch 33 in /content/checkpoint.pth
Epoch [34/50], Train Loss: 1.1783, Train Accuracy: 0.5531, Val Loss: 0.8849, Val Accuracy: 0.6967
Checkpoint saved at epoch 34 in /content/checkpoint.pth
Epoch [35/50], Train Loss: 1.1439, Train Accuracy: 0.5682, Val Loss: 0.8683, Val Accuracy: 0.6979
Epoch [36/50], Train Loss: 1.1044, Train Accuracy: 0.5849, Val Loss: 0.8572, Val Accuracy: 0.7099
Epoch [37/50], Train Loss: 1.0882, Train Accuracy: 0.5907, Val Loss: 0.8514, Val Accuracy: 0.7156
Epoch [38/50], Train Loss: 1.0870, Train Accuracy: 0.5907, Val Loss: 0.8251, Val Accuracy: 0.7184
Checkpoint saved at epoch 38 in /content/checkpoint.pth
Epoch [39/50], Train Loss: 1.0675, Train Accuracy: 0.5980, Val Loss: 0.8045, Val Accuracy: 0.7269
Checkpoint saved at epoch 39 in /content/checkpoint.pth
Epoch [40/50], Train Loss: 1.0584, Train Accuracy: 0.6042, Val Loss: 0.7975, Val Accuracy: 0.7275
Checkpoint saved at epoch 40 in /content/checkpoint.pth
Epoch [41/50], Train Loss: 1.0450, Train Accuracy: 0.6044, Val Loss: 0.7905, Val Accuracy: 0.7328
Checkpoint saved at epoch 41 in /content/checkpoint.pth
Epoch [42/50], Train Loss: 1.0286, Train Accuracy: 0.6134, Val Loss: 0.7759, Val Accuracy: 0.7371
Epoch [43/50], Train Loss: 1.0076, Train Accuracy: 0.6220, Val Loss: 0.7814, Val Accuracy: 0.7417
Checkpoint saved at epoch 43 in /content/checkpoint.pth
Epoch [44/50], Train Loss: 1.0023, Train Accuracy: 0.6248, Val Loss: 0.7728, Val Accuracy: 0.7339
Checkpoint saved at epoch 44 in /content/checkpoint.pth
Epoch [45/50], Train Loss: 0.9805, Train Accuracy: 0.6329, Val Loss: 0.7642, Val Accuracy: 0.7415
Checkpoint saved at epoch 45 in /content/checkpoint.pth
Epoch [46/50], Train Loss: 0.9606, Train Accuracy: 0.6402, Val Loss: 0.7484, Val Accuracy: 0.7463
Epoch [47/50], Train Loss: 0.9404, Train Accuracy: 0.6496, Val Loss: 0.7349, Val Accuracy: 0.7461
Checkpoint saved at epoch 47 in /content/checkpoint.pth
Epoch [48/50], Train Loss: 0.9118, Train Accuracy: 0.6578, Val Loss: 0.7290, Val Accuracy: 0.7535
Checkpoint saved at epoch 48 in /content/checkpoint.pth
Epoch [49/50], Train Loss: 0.9009, Train Accuracy: 0.6638, Val Loss: 0.7249, Val Accuracy: 0.7557
Checkpoint saved at epoch 49 in /content/checkpoint.pth
Epoch [50/50], Train Loss: 0.8910, Train Accuracy: 0.6621, Val Loss: 0.7180, Val Accuracy: 0.7539
Epoch [51/80], Train Loss: 0.8847, Train Accuracy: 0.6712, Val Loss: 0.7107, Val Accuracy: 0.7555
Epoch [52/80], Train Loss: 0.8668, Train Accuracy: 0.6726, Val Loss: 0.7139, Val Accuracy: 0.7587
Epoch [53/80], Train Loss: 0.8532, Train Accuracy: 0.6808, Val Loss: 0.7148, Val Accuracy: 0.7636
Checkpoint saved at epoch 53 in /content/checkpoint.pth
Epoch [54/80], Train Loss: 0.8381, Train Accuracy: 0.6881, Val Loss: 0.6928, Val Accuracy: 0.7640
Checkpoint saved at epoch 54 in /content/checkpoint.pth
Epoch [55/80], Train Loss: 0.8293, Train Accuracy: 0.6920, Val Loss: 0.6907, Val Accuracy: 0.7685
Epoch [56/80], Train Loss: 0.8160, Train Accuracy: 0.6994, Val Loss: 0.6971, Val Accuracy: 0.7668
Checkpoint saved at epoch 56 in /content/checkpoint.pth
Epoch [57/80], Train Loss: 0.8014, Train Accuracy: 0.7049, Val Loss: 0.6722, Val Accuracy: 0.7719
Checkpoint saved at epoch 57 in /content/checkpoint.pth
Epoch [58/80], Train Loss: 0.7828, Train Accuracy: 0.7139, Val Loss: 0.6699, Val Accuracy: 0.7725
Epoch [59/80], Train Loss: 0.7650, Train Accuracy: 0.7175, Val Loss: 0.6785, Val Accuracy: 0.7713
Epoch [60/80], Train Loss: 0.7521, Train Accuracy: 0.7247, Val Loss: 0.6709, Val Accuracy: 0.7732
Checkpoint saved at epoch 60 in /content/checkpoint.pth
Epoch [61/80], Train Loss: 0.7472, Train Accuracy: 0.7273, Val Loss: 0.6584, Val Accuracy: 0.7796
Checkpoint saved at epoch 61 in /content/checkpoint.pth
Epoch [62/80], Train Loss: 0.7286, Train Accuracy: 0.7321, Val Loss: 0.6550, Val Accuracy: 0.7827
Epoch [63/80], Train Loss: 0.7278, Train Accuracy: 0.7337, Val Loss: 0.6616, Val Accuracy: 0.7808
Epoch [64/80], Train Loss: 0.7165, Train Accuracy: 0.7415, Val Loss: 0.6653, Val Accuracy: 0.7777
Epoch [65/80], Train Loss: 0.7012, Train Accuracy: 0.7439, Val Loss: 0.6624, Val Accuracy: 0.7833
Checkpoint saved at epoch 65 in /content/checkpoint.pth
Epoch [66/80], Train Loss: 0.6791, Train Accuracy: 0.7512, Val Loss: 0.6411, Val Accuracy: 0.7892
Checkpoint saved at epoch 66 in /content/checkpoint.pth
Epoch [67/80], Train Loss: 0.6623, Train Accuracy: 0.7595, Val Loss: 0.6390, Val Accuracy: 0.7889
Checkpoint saved at epoch 67 in /content/checkpoint.pth
Epoch [68/90], Train Loss: 0.6624, Train Accuracy: 0.7593, Val Loss: 0.6407, Val Accuracy: 0.7900
Epoch [69/90], Train Loss: 0.6478, Train Accuracy: 0.7632, Val Loss: 0.6462, Val Accuracy: 0.7900
Checkpoint saved at epoch 69 in /content/checkpoint.pth
Epoch [70/90], Train Loss: 0.6369, Train Accuracy: 0.7677, Val Loss: 0.6381, Val Accuracy: 0.7919
Epoch [71/90], Train Loss: 0.6262, Train Accuracy: 0.7681, Val Loss: 0.6568, Val Accuracy: 0.7881
Checkpoint saved at epoch 71 in /content/checkpoint.pth
Epoch [72/90], Train Loss: 0.6265, Train Accuracy: 0.7716, Val Loss: 0.6332, Val Accuracy: 0.7951
Epoch [73/90], Train Loss: 0.6084, Train Accuracy: 0.7768, Val Loss: 0.6469, Val Accuracy: 0.7936
Epoch [74/90], Train Loss: 0.6129, Train Accuracy: 0.7756, Val Loss: 0.6490, Val Accuracy: 0.7903
Epoch [75/90], Train Loss: 0.5955, Train Accuracy: 0.7812, Val Loss: 0.6458, Val Accuracy: 0.7911
Epoch [76/90], Train Loss: 0.5901, Train Accuracy: 0.7838, Val Loss: 0.6425, Val Accuracy: 0.7940
Epoch [77/90], Train Loss: 0.5865, Train Accuracy: 0.7852, Val Loss: 0.6350, Val Accuracy: 0.7984
Epoch [78/90], Train Loss: 0.5661, Train Accuracy: 0.7936, Val Loss: 0.6351, Val Accuracy: 0.7987
Checkpoint saved at epoch 78 in /content/checkpoint.pth
Epoch [79/90], Train Loss: 0.5620, Train Accuracy: 0.7955, Val Loss: 0.6327, Val Accuracy: 0.8003
Checkpoint saved at epoch 79 in /content/checkpoint.pth
Epoch [80/90], Train Loss: 0.5535, Train Accuracy: 0.7997, Val Loss: 0.6285, Val Accuracy: 0.7987
Epoch [81/90], Train Loss: 0.5468, Train Accuracy: 0.7977, Val Loss: 0.6376, Val Accuracy: 0.8004
Epoch [82/90], Train Loss: 0.5443, Train Accuracy: 0.8022, Val Loss: 0.6441, Val Accuracy: 0.8005
Epoch [83/90], Train Loss: 0.5370, Train Accuracy: 0.8024, Val Loss: 0.6629, Val Accuracy: 0.7917
Epoch [84/90], Train Loss: 0.5305, Train Accuracy: 0.8064, Val Loss: 0.6413, Val Accuracy: 0.8000
Epoch [85/90], Train Loss: 0.5164, Train Accuracy: 0.8102, Val Loss: 0.6355, Val Accuracy: 0.8004
Epoch [86/90], Train Loss: 0.5199, Train Accuracy: 0.8116, Val Loss: 0.6336, Val Accuracy: 0.8039
Checkpoint saved at epoch 86 in /content/checkpoint.pth
Epoch [87/90], Train Loss: 0.5129, Train Accuracy: 0.8131, Val Loss: 0.6278, Val Accuracy: 0.8013
Epoch [88/90], Train Loss: 0.5022, Train Accuracy: 0.8159, Val Loss: 0.6379, Val Accuracy: 0.8012
Epoch [89/90], Train Loss: 0.4935, Train Accuracy: 0.8181, Val Loss: 0.6315, Val Accuracy: 0.8057
Epoch [90/90], Train Loss: 0.4912, Train Accuracy: 0.8197, Val Loss: 0.6351, Val Accuracy: 0.8007
"""

# Lists to store the extracted data
train_losses, val_losses = [], []  # Lists for train and validation losses
train_accuracies, val_accuracies = [], []  # Lists for train and validation accuracies

# Extract data from the training log
for line in log.strip().split("\n"):  # Iterate over each line in the log
    if "Epoch [" in line:  # Check if the line contains epoch information
        parts = line.split(", ")  # Split the line into parts using ', ' as a separator
        train_loss = float(parts[1].split(":")[1].strip())  # Extract train loss
        train_acc = float(parts[2].split(":")[1].strip())  # Extract train accuracy
        val_loss = float(parts[3].split(":")[1].strip())  # Extract validation loss
        val_acc = float(parts[4].split(":")[1].strip())  # Extract validation accuracy

        # Append the extracted values to the corresponding lists
        train_losses.append(train_loss)
        val_losses.append(val_loss)
        train_accuracies.append(train_acc)
        val_accuracies.append(val_acc)
# Check and fill missing epochs
for i in range(1, 50):  # Iterate through expected epoch numbers
    if i not in range(1, len(train_losses) + 1):  # Check if an epoch is missing in the data
        # Fill missing epoch using interpolation between neighboring epochs
        train_losses.insert(i - 1, (train_losses[i - 2] + train_losses[i]) / 2)  # Interpolate train loss
        val_losses.insert(i - 1, (val_losses[i - 2] + val_losses[i]) / 2)        # Interpolate validation loss
        train_accuracies.insert(i - 1, (train_accuracies[i - 2] + train_accuracies[i]) / 2)  # Interpolate train accuracy
        val_accuracies.insert(i - 1, (val_accuracies[i - 2] + val_accuracies[i]) / 2)        # Interpolate validation accuracy

import matplotlib.pyplot as plt  # Import Matplotlib for plotting

# Plotting the graph
plt.figure(figsize=(10, 4))  # Create a figure with specified size

# Loss graph
plt.subplot(1, 2, 1)  # Create the first subplot for losses
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')  # Plot train loss
plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')  # Plot validation loss
plt.xlabel('Epoch')  # Label for the x-axis
plt.ylabel('Loss')  # Label for the y-axis
plt.legend()  # Add legend to differentiate between train and validation
plt.title('Loss vs Epochs')  # Title for the loss graph

# Accuracy graph
plt.subplot(1, 2, 2)  # Create the second subplot for accuracies
plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy')  # Plot train accuracy
plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Validation Accuracy')  # Plot validation accuracy
plt.xlabel('Epoch')  # Label for the x-axis
plt.ylabel('Accuracy')  # Label for the y-axis
plt.legend()  # Add legend to differentiate between train and validation
plt.title('Accuracy vs Epochs')  # Title for the accuracy graph

plt.tight_layout()  # Adjust layout to prevent overlap between plots
plt.show()  # Display the graphs